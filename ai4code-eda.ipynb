{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/jasonsgraham/nlp_notes/blob/main/nlp_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Setup #","metadata":{"id":"rqyINkDrImYK"}},{"cell_type":"code","source":"# %%sh\n# pip install -q --upgrade transformers\n# pip install -q --upgrade wandb\n# pip install -q --upgrade mlflow","metadata":{"id":"XmCqytz54Ksv","execution":{"iopub.status.busy":"2022-07-01T16:27:45.187282Z","iopub.execute_input":"2022-07-01T16:27:45.188693Z","iopub.status.idle":"2022-07-01T16:28:44.614413Z","shell.execute_reply.started":"2022-07-01T16:27:45.188648Z","shell.execute_reply":"2022-07-01T16:28:44.612732Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 4.20.1 which is incompatible.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 4.20.1 which is incompatible.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Check if notebook is running in Colab or Kaggle","metadata":{"id":"wskI0TGcKDPd"}},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom tqdm import tqdm\n\npd.options.display.width = 180\npd.options.display.max_colwidth = 120\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 500)\npd.set_option('display.max_rows', 500)","metadata":{"jupyter":{"outputs_hidden":false},"id":"SOkVZopeImYL","collapsed":false,"execution":{"iopub.status.busy":"2022-07-01T16:51:30.060034Z","iopub.execute_input":"2022-07-01T16:51:30.060524Z","iopub.status.idle":"2022-07-01T16:51:30.068826Z","shell.execute_reply.started":"2022-07-01T16:51:30.060487Z","shell.execute_reply":"2022-07-01T16:51:30.067162Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import sys\nGOOGLE_COLAB = 'google.colab' in sys.modules\n\nif GOOGLE_COLAB:\n  data_dir = Path('/content/drive/MyDrive/Colab Notebooks/input/AI4Code')\n  output_dir = Path('/content/drive/MyDrive/Colab Notebooks/output/AI4Code')\n  train_parquet_file = data_dir / 'train.parquet'\nelse:\n  data_dir = data_dir = Path('../input/AI4Code')\n  output_dir = Path('./')\n  train_parquet_file = Path('../input/trainparquet/train.parquet')","metadata":{"id":"GMj7yuuZvr2k","execution":{"iopub.status.busy":"2022-07-01T16:49:06.158527Z","iopub.execute_input":"2022-07-01T16:49:06.158970Z","iopub.status.idle":"2022-07-01T16:49:06.165992Z","shell.execute_reply.started":"2022-07-01T16:49:06.158936Z","shell.execute_reply":"2022-07-01T16:49:06.164839Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Ordering the Cells #","metadata":{"id":"tzjH1bHqImYP"}},{"cell_type":"code","source":"df_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split()  # Split the string representation of cell_ids into a list\n\ndf_orders","metadata":{"jupyter":{"outputs_hidden":false},"id":"bryA-XdoImYQ","collapsed":false,"execution":{"iopub.status.busy":"2022-07-01T16:51:37.386322Z","iopub.execute_input":"2022-07-01T16:51:37.386741Z","iopub.status.idle":"2022-07-01T16:51:40.304811Z","shell.execute_reply.started":"2022-07-01T16:51:37.386708Z","shell.execute_reply":"2022-07-01T16:51:40.303512Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"id\n00001756c60be8    [1862f0a6, 448eb224, 2a9e43d6, 7e2f170a, 038b763d, 77e56113, 2eefe0ef, 1ae087ab, 0beab1cd, 8ffe0b25, 9a78ab76, 0d136...\n00015c83e2717b    [2e94bd7a, 3e99dee9, b5e286ea, da4f7550, c417225b, 51e3cd89, 2600b4eb, 75b65993, cf195f8b, 25699d02, 72b3201a, f2c75...\n0001bdd4021779    [3fdc37be, 073782ca, 8ea7263c, 80543cd8, 38310c80, 073e27e5, 015d52a4, ad7679ef, 7fde4f04, 07c52510, 0a1a7a39, 0bcd3...\n0001daf4c2c76d    [97266564, a898e555, 86605076, 76cc2642, ef279279, df6c939f, 2476da96, 00f87d0a, ae93e8e6, 58aadb1d, d20b0094, 986fd...\n0002115f48f982                                 [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe576, a3188e54, b3f6e12d, ee7655ca, 84125b7a]\n                                                                           ...                                                           \nfffc30d5a0bc46    [09727c0c, ff1ea6a0, ddfef603, a01ce9b3, 3ba953ee, bf92a015, f4a0492a, 095812e6, 53125cfe, aa32a700, 63340e73, 06d8c...\nfffc3b44869198    [978a5137, faa48f03, 28dfb12a, eea2e812, 64fef97c, 4e0d1510, 58e68f2c, 8784e700, 4bd5a4cf, dc14bfec, 2aff7603, 8047d...\nfffc63ff750064    [5015c300, 411b85d9, 8238198c, f4781d1d, b5532930, e1f223e5, e7e67119, 4aaf741d, 7229cce6, a7fa3628, e4c2fa86, 1f8f9...\nfffcd063cda949    [7e6266ad, d8281fc5, d4ffcaef, 3e0e4a47, 21387fc8, cc229f9a, baed9c8b, d1bb21aa, 82979992, 65f95dad, eba4fa9e, c97e2...\nfffe1d764579d5    [1a63248d, 9c3b96a5, 1398a873, 4e2d4c2d, f71c538e, 8b44a5e8, 385dff7a, b8254ef8, 4d0e433e, debc496c, e15ae953, e4d79...\nName: cell_order, Length: 139256, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"NUM_TRAIN = 10000\n\n\ndef read_notebook(path):\n    return (\n        pd.read_json(\n            path,\n            dtype={'cell_type': 'category', 'source': 'str'})\n        .assign(id=path.stem)\n        .rename_axis('cell_id')\n    )\n\nif train_parquet_file.exists():\n  df = pd.read_parquet(train_parquet_file)\nelse:\n  paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n  notebooks_train = [\n      read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n  ]\n  df = (\n      pd.concat(notebooks_train)\n      .set_index('id', append=True)\n      .swaplevel()\n      .sort_index(level='id', sort_remaining=False)\n  )\n  #df.to_parquet(train_parquet_file)","metadata":{"jupyter":{"outputs_hidden":false},"id":"itkesgMJImYN","collapsed":false,"execution":{"iopub.status.busy":"2022-07-01T16:49:12.337248Z","iopub.execute_input":"2022-07-01T16:49:12.337677Z","iopub.status.idle":"2022-07-01T16:49:16.857804Z","shell.execute_reply.started":"2022-07-01T16:49:12.337643Z","shell.execute_reply":"2022-07-01T16:49:16.856665Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df_orders.shape","metadata":{"id":"Z_z4yBk3Si5n","outputId":"cccc9101-52ae-481f-cd79-6bddc2a19b7c","execution":{"iopub.status.busy":"2022-07-01T16:49:28.548974Z","iopub.execute_input":"2022-07-01T16:49:28.550735Z","iopub.status.idle":"2022-07-01T16:49:28.561030Z","shell.execute_reply.started":"2022-07-01T16:49:28.550683Z","shell.execute_reply":"2022-07-01T16:49:28.559481Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(139256,)"},"metadata":{}}]},{"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\ndf","metadata":{"id":"LLVxZqFBS610","execution":{"iopub.status.busy":"2022-07-01T16:52:51.960569Z","iopub.execute_input":"2022-07-01T16:52:51.961001Z","iopub.status.idle":"2022-07-01T16:52:51.983116Z","shell.execute_reply.started":"2022-07-01T16:52:51.960963Z","shell.execute_reply":"2022-07-01T16:52:51.981480Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                        cell_type                                                                                                                   source\nid             cell_id                                                                                                                                    \n0002115f48f982 18281c6c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\nimport ...\n               e3b6b115      code                                                               df = pd.read_csv('../input/metadata_train.csv')\\ndf.info()\n               4a044c54      code                                                                                                                df.head()\n               365fe576      code  #let's check if targets are consistent within the same measurement id\\ntargets = df.groupby('id_measurement')[['targ...\n               a3188e54      code  sns.countplot(x='target',data=targets)\\n# it should be only \"1\" and \"0\" but we have cases where target is not consit...\n...                           ...                                                                                                                      ...\nffe8d0aa5e7d68 b9f0782a  markdown                                                                                                            ### Modelling\n               3492f280  markdown  Now one of the important step in this task, we know that this is a regression task, previously we seen skewness in o...\n               eea09e6e  markdown  We will made our regression model, now we have come to end our task, in this section we will capture some parameter ...\n               54ffd613  markdown                                                                                                                ### Ridge\n               3c645477  markdown                                                                                                         #### Ridge Model\n\n[453294 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>cell_type</th>\n      <th>source</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th>cell_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0002115f48f982</th>\n      <th>18281c6c</th>\n      <td>code</td>\n      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\nimport ...</td>\n    </tr>\n    <tr>\n      <th>e3b6b115</th>\n      <td>code</td>\n      <td>df = pd.read_csv('../input/metadata_train.csv')\\ndf.info()</td>\n    </tr>\n    <tr>\n      <th>4a044c54</th>\n      <td>code</td>\n      <td>df.head()</td>\n    </tr>\n    <tr>\n      <th>365fe576</th>\n      <td>code</td>\n      <td>#let's check if targets are consistent within the same measurement id\\ntargets = df.groupby('id_measurement')[['targ...</td>\n    </tr>\n    <tr>\n      <th>a3188e54</th>\n      <td>code</td>\n      <td>sns.countplot(x='target',data=targets)\\n# it should be only \"1\" and \"0\" but we have cases where target is not consit...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">ffe8d0aa5e7d68</th>\n      <th>b9f0782a</th>\n      <td>markdown</td>\n      <td>### Modelling</td>\n    </tr>\n    <tr>\n      <th>3492f280</th>\n      <td>markdown</td>\n      <td>Now one of the important step in this task, we know that this is a regression task, previously we seen skewness in o...</td>\n    </tr>\n    <tr>\n      <th>eea09e6e</th>\n      <td>markdown</td>\n      <td>We will made our regression model, now we have come to end our task, in this section we will capture some parameter ...</td>\n    </tr>\n    <tr>\n      <th>54ffd613</th>\n      <td>markdown</td>\n      <td>### Ridge</td>\n    </tr>\n    <tr>\n      <th>3c645477</th>\n      <td>markdown</td>\n      <td>#### Ridge Model</td>\n    </tr>\n  </tbody>\n</table>\n<p>453294 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"nb_id = df.index.unique('id')[6]\n# Get the correct order\ncell_order = df_orders.loc[nb_id]\nnb = df.loc[nb_id, :]\nprint(\"The ordered notebook:\")\n#nb.loc[cell_order, :]\ncell_order","metadata":{"id":"Lu8WpJbXTDXb","outputId":"3adf4f4d-de57-492d-b08e-92c4861e407e","execution":{"iopub.status.busy":"2022-07-01T16:42:07.191208Z","iopub.execute_input":"2022-07-01T16:42:07.191679Z","iopub.status.idle":"2022-07-01T16:42:07.217222Z","shell.execute_reply.started":"2022-07-01T16:42:07.191633Z","shell.execute_reply":"2022-07-01T16:42:07.216259Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"The ordered notebook:\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['91d97bb2',\n '4e6f32f6',\n '0aeca210',\n 'cadfdb16',\n 'fe39c117',\n 'bbc5f229',\n '91194a54',\n '46cc92d1',\n '9d6ea72b',\n 'd0f88604',\n '8df28832',\n 'd3345791',\n '8c01934e',\n '18b4e8d6',\n 'c012109d',\n '83ff0598',\n 'd35f13e5',\n 'cfba39db',\n 'fbc1c206',\n 'ace03b55',\n '671b78af',\n '61d3ad05',\n '6d6683ea',\n '2f41ebe2',\n '9dae7ae9']"},"metadata":{}}]},{"cell_type":"code","source":"def get_ranks(base, derived):\n    return [base.index(d) for d in derived]\n\ncell_ranks = get_ranks(cell_order, list(nb.index))\nnb.insert(0, 'rank', cell_ranks)\n\nnb","metadata":{"id":"s-usviEgUbBH","outputId":"d7379520-ec13-4776-b83a-2c456a13f501","execution":{"iopub.status.busy":"2022-07-01T16:46:12.544077Z","iopub.execute_input":"2022-07-01T16:46:12.544457Z","iopub.status.idle":"2022-07-01T16:46:12.579210Z","shell.execute_reply.started":"2022-07-01T16:46:12.544426Z","shell.execute_reply":"2022-07-01T16:46:12.577963Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/73178946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mderived\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcell_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/73178946.py\u001b[0m in \u001b[0;36mget_ranks\u001b[0;34m(base, derived)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mderived\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcell_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/73178946.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderived\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mderived\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcell_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ranks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: '4e6f32f6' is not in list"],"ename":"ValueError","evalue":"'4e6f32f6' is not in list","output_type":"error"}]},{"cell_type":"code","source":"from pandas.testing import assert_frame_equal\n\nassert_frame_equal(nb.loc[cell_order, :], nb.sort_values('rank'))","metadata":{"id":"iQi1NaDgVRgX","execution":{"iopub.status.busy":"2022-07-01T16:43:09.273826Z","iopub.execute_input":"2022-07-01T16:43:09.274220Z","iopub.status.idle":"2022-07-01T16:43:09.286311Z","shell.execute_reply.started":"2022-07-01T16:43:09.274188Z","shell.execute_reply":"2022-07-01T16:43:09.284832Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_orders_ = df_orders.to_frame().join(\n    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n    how='right',\n)\n\nranks = {}\nfor id_, cell_order, cell_id in df_orders_.itertuples():\n    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n\ndf_ranks = (\n    pd.DataFrame\n    .from_dict(ranks, orient='index')\n    .rename_axis('id')\n    .apply(pd.Series.explode)\n    .set_index('cell_id', append=True)\n)\n\ndf_ranks","metadata":{"id":"g03vdZiCViUT","outputId":"7a3eb802-4106-4958-ed2e-52127d8b0920","execution":{"iopub.status.busy":"2022-07-01T16:43:54.484031Z","iopub.execute_input":"2022-07-01T16:43:54.484433Z","iopub.status.idle":"2022-07-01T16:43:57.672812Z","shell.execute_reply.started":"2022-07-01T16:43:54.484400Z","shell.execute_reply":"2022-07-01T16:43:57.671519Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                        rank\nid             cell_id      \n000c0a9b2fef4d 1087237d    2\n               d7209f1f    4\n               daf5b8ee    6\n               e404213c    7\n               2bad59b0    8\n...                      ...\nfffc63ff750064 56aa8da7   25\n               411b85d9    1\n               e7e67119    6\n               8b54cf58   22\n               b3c6bc16   18\n\n[461166 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>rank</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th>cell_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">000c0a9b2fef4d</th>\n      <th>1087237d</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>d7209f1f</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>daf5b8ee</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>e404213c</th>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2bad59b0</th>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">fffc63ff750064</th>\n      <th>56aa8da7</th>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>411b85d9</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>e7e67119</th>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8b54cf58</th>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>b3c6bc16</th>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>461166 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Splits #","metadata":{"id":"CGAgYp9IImYS"}},{"cell_type":"markdown","source":"The `df_ancestors.csv` file identifies groups of notebooks derived from a common origin, that is, notebooks belonging to the same forking tree.","metadata":{"id":"42eItQZchsnT"}},{"cell_type":"code","source":"df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')","metadata":{"id":"3TzvAwSyVpyA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ancestors","metadata":{"id":"mnOn0YpiVy6I","outputId":"0314bb07-3a08-454b-a039-4cd605a5de22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\n\nNVALID = 0.1  # size of validation set\n\nsplitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n\n# Split, keeping notebooks with a common origin (ancestor_id) together\nids = df.index.unique('id')\nancestors = df_ancestors.loc[ids, 'ancestor_id']\nids_train, ids_valid = next(splitter.split(ids, groups=ancestors))\nids_train, ids_valid = ids[ids_train], ids[ids_valid]\n\ndf_train = df.loc[ids_train, :]\ndf_valid = df.loc[ids_valid, :]","metadata":{"id":"0_lV8Hu1V1N0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_valid","metadata":{"id":"aY5GBdVOWfn3","outputId":"28544878-72c5-464a-8448-659b0002ceb8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering #\n\nLet's generate [tf-idf features](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer) to use with our ranking model. These features will help our model learn what kinds of words tend to occur most often at various positions within a notebook.","metadata":{"id":"aQ8y8KDdImYT"}},{"cell_type":"markdown","source":"## AI4Code Extract all functions, variables... names\n\n\n(see, https://www.kaggle.com/code/haithamaliryan/ai4code-extract-all-functions-variables-names) Upvote if this is useful to you.","metadata":{"id":"rDYFCDZnWImC"}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Training set\ntfidf = TfidfVectorizer(min_df=0.01)\nX_train = tfidf.fit_transform(df_train['source'].astype(str))\n# Rank of each cell within the notebook\ny_train = df_ranks.loc[ids_train].to_numpy()\n# Number of cells in each notebook\ngroups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:29:46.318074Z","iopub.execute_input":"2022-06-22T20:29:46.318351Z","iopub.status.idle":"2022-06-22T20:29:58.892557Z","shell.execute_reply.started":"2022-06-22T20:29:46.318322Z","shell.execute_reply":"2022-06-22T20:29:58.891665Z"},"id":"8noqbAwKImYT","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's add the code cell ordering as a feature. We'll append a column that enumerates the code cells in the correct order, like `1, 2, 3, 4, ...`, while having the dummy value `0` for all markdown cells. This feature will help the model learn to put the code cells in the correct order.","metadata":{"id":"t_Kyp01rImYU"}},{"cell_type":"code","source":"code=nb.loc[nb.cell_type==\"code\"]","metadata":{"id":"UKNxRK1gTHBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"code","metadata":{"id":"Ox6AnMJsalRf","outputId":"9d686adf-1e64-44d3-d83d-c09063be694f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tokenize\nimport io\n\ncode.loc['33ff3073','source']\n\ncode_text = tokenize.generate_tokens(io.StringIO(code.loc['33ff3073','source']).readline)\n[tok for tok in code_text]","metadata":{"id":"CkNRp-ZNSpSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract only function names, variables, comments then we can join them\ncode_text = tokenize.generate_tokens(io.StringIO(code.loc['33ff3073','source']).readline)\n[tok.string for tok in code_text if tok.type==53 or tok.type==55]","metadata":{"id":"tlIYC8gKS7Nu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add code cell ordering\nX_train = sparse.hstack((\n    X_train,\n    np.where(\n        df_train['cell_type'] == 'code',\n        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n        0,\n    ).reshape(-1, 1)\n))\n\nprint(X_train.shape)","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:30:33.186339Z","iopub.execute_input":"2022-06-22T20:30:33.186647Z","iopub.status.idle":"2022-06-22T20:30:33.430938Z","shell.execute_reply.started":"2022-06-22T20:30:33.186618Z","shell.execute_reply":"2022-06-22T20:30:33.430056Z"},"id":"Mg67oNAMImYU","outputId":"a2341816-7dc3-45e6-ca96-5009b29d9e9f","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"HV4uQqTna3hr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train #","metadata":{"id":"sPgHHAhEImYU"}},{"cell_type":"markdown","source":"We'll use the ranking algorithm provided by XGBoost.","metadata":{"id":"M7f4gMqQImYU"}},{"cell_type":"code","source":"from xgboost import XGBRanker\n\nmodel = XGBRanker(\n    min_child_weight=10,\n    subsample=0.5,\n    tree_method='hist',\n)\n\nmodel.fit(X_train, y_train, group=groups)","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:32:00.517896Z","iopub.execute_input":"2022-06-22T20:32:00.518178Z","iopub.status.idle":"2022-06-22T20:32:12.757784Z","shell.execute_reply.started":"2022-06-22T20:32:00.518141Z","shell.execute_reply":"2022-06-22T20:32:12.757030Z"},"id":"JZqI4KQwImYU","outputId":"d319ddd0-f7bd-4cf4-e089-6621f22f128c","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate #","metadata":{"id":"t8W3kXArImYU"}},{"cell_type":"markdown","source":"Now let's see how well our model learned to order Kaggle notebook cells. We'll evaluate predictions on the validation set with a variant of the Kendall tau correlation.","metadata":{"id":"WYPByi39ImYU"}},{"cell_type":"markdown","source":"## Validation set ##","metadata":{"id":"DzTHfi7LImYV"}},{"cell_type":"markdown","source":"First we'll create features for the validation set just like we did for the training set.","metadata":{"id":"y9WfdeafImYV"}},{"cell_type":"code","source":"# Validation set\nX_valid = tfidf.transform(df_valid['source'].astype(str))\n# The metric uses cell ids\ny_valid = df_orders.loc[ids_valid]\n\nX_valid = sparse.hstack((\n    X_valid,\n    np.where(\n        df_valid['cell_type'] == 'code',\n        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n        0,\n    ).reshape(-1, 1)\n))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:33:11.120661Z","iopub.execute_input":"2022-06-22T20:33:11.121542Z","iopub.status.idle":"2022-06-22T20:33:12.405417Z","shell.execute_reply.started":"2022-06-22T20:33:11.121491Z","shell.execute_reply":"2022-06-22T20:33:12.404524Z"},"id":"nhYeY8JrImYV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we'll use the model to predict the rank of each cell within its notebook and then convert these ranks into a list of ordered cell ids.","metadata":{"id":"BGnny9G5ImYV"}},{"cell_type":"code","source":"y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\ny_pred = (\n    y_pred\n    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n                                  # The cell_ids are now in the order the model predicted.\n    .reset_index('cell_id')  # Convert the cell_id index into a column.\n    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n)\ny_pred.head(10)","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:34:31.373247Z","iopub.execute_input":"2022-06-22T20:34:31.373581Z","iopub.status.idle":"2022-06-22T20:34:31.542514Z","shell.execute_reply.started":"2022-06-22T20:34:31.373546Z","shell.execute_reply":"2022-06-22T20:34:31.541588Z"},"id":"OArdlUG0ImYW","outputId":"13c8313b-12dd-4270-d2c2-366a25f332c2","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's examine a notebook to see how the model did.","metadata":{"id":"pQLf6yqyImYW"}},{"cell_type":"code","source":"nb_id = df_valid.index.get_level_values('id').unique()[8]\n\ndisplay(df.loc[nb_id])\ndisplay(df.loc[nb_id].loc[y_pred.loc[nb_id]])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:34:36.003759Z","iopub.execute_input":"2022-06-22T20:34:36.004055Z","iopub.status.idle":"2022-06-22T20:34:36.031403Z","shell.execute_reply.started":"2022-06-22T20:34:36.004023Z","shell.execute_reply":"2022-06-22T20:34:36.030730Z"},"id":"6BSy0XnjImYW","outputId":"20e574f4-a5a1-47bc-8ec3-fb8e3561e1b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metric ##\n\nThis competition uses a variant of the [Kendall tau correlation](https://www.kaggle.com/competitions/AI4Code/overview/evaluation), which will measure how close to the correct order our predicted orderings are. See this notebook for more on this metric: [Competition Metric - Kendall Tau Correlation](https://www.kaggle.com/code/ryanholbrook/competition-metric-kendall-tau-correlation/notebook).","metadata":{"id":"cicfvDq0ImYW"}},{"cell_type":"code","source":"from bisect import bisect\n\n\ndef count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:34:53.477544Z","iopub.execute_input":"2022-06-22T20:34:53.477801Z","iopub.status.idle":"2022-06-22T20:34:53.484700Z","shell.execute_reply.started":"2022-06-22T20:34:53.477776Z","shell.execute_reply":"2022-06-22T20:34:53.483876Z"},"id":"__nbz1HkImYW","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's test the metric with a dummy submission created from the ids of the shuffled notebooks.","metadata":{"id":"Wrry0NlhImYX"}},{"cell_type":"code","source":"y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\ndummy_score = kendall_tau(y_valid, y_dummy)\n\nmlflow.log_metric(\"Dummy_Score\", dummy_score)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:35:01.191031Z","iopub.execute_input":"2022-06-22T20:35:01.191787Z","iopub.status.idle":"2022-06-22T20:35:01.300195Z","shell.execute_reply.started":"2022-06-22T20:35:01.191744Z","shell.execute_reply":"2022-06-22T20:35:01.299305Z"},"id":"P6BRnx0iImYX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing this to the score on the predictions, we can see that our model was indeed able to improve the cell ordering somewhat.","metadata":{"id":"eh1J1IjzImYX"}},{"cell_type":"code","source":"prediction_score = kendall_tau(y_valid, y_pred)\nmlflow.log_metric(\"Prediction_Score\", prediction_score)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:35:03.909161Z","iopub.execute_input":"2022-06-22T20:35:03.909457Z","iopub.status.idle":"2022-06-22T20:35:03.976512Z","shell.execute_reply.started":"2022-06-22T20:35:03.909424Z","shell.execute_reply":"2022-06-22T20:35:03.975663Z"},"id":"CcXG8FcDImYX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Kr2VQbWliXHD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission #","metadata":{"id":"cZEXEp3bImYY"}},{"cell_type":"markdown","source":"To create a submission for this competition, we'll apply our model to the notebooks in the test set. Note that this is a **Code Competition**, which means that the test data we see here is only a small sample. When we submit our notebook for scoring, this example data will be replaced with the full test set of about 20,000 notebooks.","metadata":{"id":"bkN1ZrZDImYY"}},{"cell_type":"markdown","source":"First we load the data.","metadata":{"id":"PI9gXwDlImYY"}},{"cell_type":"code","source":"paths_test = list((data_dir / 'test').glob('*.json'))\nnotebooks_test = [\n    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n]\ndf_test = (\n    pd.concat(notebooks_test)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T20:35:21.716153Z","iopub.execute_input":"2022-06-22T20:35:21.716457Z","iopub.status.idle":"2022-06-22T20:35:21.791111Z","shell.execute_reply.started":"2022-06-22T20:35:21.716417Z","shell.execute_reply":"2022-06-22T20:35:21.790432Z"},"id":"m2TlSna4ImYY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then create the tf-idf and code cell features.","metadata":{"id":"LsGnDZMGImYY"}},{"cell_type":"code","source":"X_test = tfidf.transform(df_test['source'].astype(str))\nX_test = sparse.hstack((\n    X_test,\n    np.where(\n        df_test['cell_type'] == 'code',\n        df_test.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n        0,\n    ).reshape(-1, 1)\n))","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:35:26.507891Z","iopub.execute_input":"2022-06-22T20:35:26.508174Z","iopub.status.idle":"2022-06-22T20:35:26.523772Z","shell.execute_reply.started":"2022-06-22T20:35:26.508142Z","shell.execute_reply":"2022-06-22T20:35:26.522941Z"},"id":"EFH2g4XFImYY","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And then create predictions on the test set.","metadata":{"id":"1A8G96pyImYY"}},{"cell_type":"code","source":"y_infer = pd.DataFrame({'rank': model.predict(X_test)}, index=df_test.index)\ny_infer = y_infer.sort_values(['id', 'rank']).reset_index('cell_id').groupby('id')['cell_id'].apply(list)\ny_infer","metadata":{"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-22T20:35:34.132890Z","iopub.execute_input":"2022-06-22T20:35:34.133563Z","iopub.status.idle":"2022-06-22T20:35:34.153489Z","shell.execute_reply.started":"2022-06-22T20:35:34.133516Z","shell.execute_reply":"2022-06-22T20:35:34.152650Z"},"id":"3HVhRP8qImYZ","collapsed":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `sample_submission.csv` file shows what a correctly formatted submission must look like. We'll just use it as a visual check, but you might like to directly modify the values of sample submission instead. (This would help prevent failed submissions due to missing notebook ids or incorrectly named columns, for instance.)","metadata":{"id":"075A29SWImYZ"}}]}